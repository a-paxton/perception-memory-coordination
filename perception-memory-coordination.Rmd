---
title: "Interpersonal coordination in perception and memory"
author: "A. Paxton, T. J. H. Morgan, J. Suchow, & T. L. Griffiths"
output: 
  html_document:
    number_sections: true
    keep_md: true
---

This R markdown provides the basis for our manuscript, "Interpersonal coordination in perception and memory" (Paxton, Morgan, Suchow & Griffiths, *in peparation*).

To run these analyses from scratch, you will need the following files:

* `./data/`: Contains experimental data. All data for included dyads are freely available in the OSF repository for the project: `https://osf.io/8fu7x/`.
* `./supplementary-code/required_packages-pmc.r`: Installs required libraries, if they are not already installed. **NOTE**: This should be run *before* running this script.
* `./supplementary-code/libraries_and_functions-pmc.r`: Loads in necessary libraries and creates new functions for our analyses.

Additional files will be created during the initial run that will help reduce processing time. Several of these files are available as CSVs from the OSF repository listed above.

**Written by**: A. Paxton (University of California, Berkeley)
<br>**Date last modified**: 19 October 2017

***

# Data preparation

***

## Preliminaries

```{r prep-prelim, warning = FALSE, error = FALSE, message = FALSE}

# clear our workspace
rm(list=ls())

# read in libraries and create functions
source('./supplementary-code/required_packages-pmc.r')
source('./supplementary-code/libraries_and_functions-pmc.r')

```

***

## Concatenate experiment files

```{r concatenate-data, warning = FALSE, error = FALSE, message = FALSE}

# get list of individual experiments included in the data
experiment_files = list.dirs('./data', recursive=FALSE)

# concatenate the files
vector_files = data.frame()
info_files = data.frame()
for (experiment in experiment_files){
  
  # read in the next experiment's files and add ID to each
  exp_id = strsplit(as.character(experiment),"/|-")[[1]][3]
  next_vector = read.table(paste(experiment,'/vector.csv',sep=''), sep=',',
                           header=TRUE, stringsAsFactors = FALSE) %>%
    mutate(experiment = exp_id)
  next_info = read.table(paste(experiment,'/info.csv',sep=''), sep=',',
                         header=TRUE, stringsAsFactors = FALSE) %>%
    mutate(experiment = exp_id)

  # append to group files
  vector_files = rbind.data.frame(vector_files, next_vector)
  info_files = rbind.data.frame(info_files, next_info)
}

```

## Identify dyads from vector data

In order to figure out which participants' nodes were connected to one another in dyads, we use the vectors created between nodes (excluding the stimulus-creating node). We then use that information to identify which stimuli were sent to which dyads.

```{r identify-dyads, warning = FALSE, error = FALSE, message = FALSE}

# use the vectors connecting the nodes to identify pairs
vector_df = vector_files %>%
  
  # convert time to integer and winnow out unnecessary variables and nodes
  mutate(t = round(as.numeric(ymd_hms(creation_time)), 0)) %>%
  select(experiment, t, origin_id, destination_id, network_id) %>%
  dplyr::filter(!origin_id == 1) %>%
  
  # find pairs from vector files
  group_by(experiment, t) %>%
  mutate(min_id = pmin(origin_id,destination_id)) %>%
  mutate(max_id = pmax(origin_id,destination_id)) %>%
  ungroup() %>%
  
  # get unique pairs and number them
  select(-origin_id, -destination_id) %>%
  distinct() %>%
  mutate(dyad = seq_along(min_id)) %>%

  # gather the participants into a single column
  gather(key="id",value="participant", min_id, max_id) %>%
  select(-id)

# figure out which stimuli were sent to which dyads
dyad_df = info_files %>%
  mutate(t = round(as.numeric(ymd_hms(creation_time)), 0)) %>%
  dplyr::filter(origin_id == 1) %>%
  select(experiment, t, contents) %>%
  full_join(., vector_df,
            by = c('experiment', 't')) %>%
  select(-t)

```

## Prepare dataframe

We now take the concatenated files and begin processing, including de-duplication of dataset.

The structure of the experiment sometimes led to near-duplicate rows to be sent to the server to manage partner communication. We must now identify these near-duplicates and strip them out. We can best identify these by using the `response_counter` variable: A properly de-duplicated dataset should have only 1 row per `response_counter` value in each trial for each participant.

```{r process-infos, warning = FALSE, error = FALSE, message = FALSE}

# load in infos
info_df = info_files %>%
  
  # filter out stimulus nodes
  dplyr::filter(!origin_id == 1) %>%
  
  # convert time and get rid of unnecessary variables
  mutate(t = round(as.numeric(ymd_hms(creation_time)), 0)) %>%
  select(experiment, t, property3, origin_id, network_id, contents) %>%
  
  # read in `contents` as JSONs and nix the JSON column
  cbind(.,
        jsonlite::stream_in(textConnection(.$contents))) %>%
  select(-contents) %>%
  
  # merge info datafarme with dyad number information
  full_join(., dyad_df,
            by = c('experiment', 'origin_id')) %>%
  
  # rename a whole slew of variables
  dplyr::rename(participant = origin_id,
                stimulus_list = contents,
                trial_type = trialType,
                trial_number = trialNumber,
                guess_counter = guessCounter,
                response_counter = responseCounter,
                accept_type = acceptType,
                response_type = responseType) %>%
  
  # get rid of unnecessary variables, get unique columns, and arrange dataframe
  select(-property3, -finalAccuracy) %>%
  distinct() %>%
  dplyr::arrange(experiment, dyad, participant, trial_number, response_counter) %>%
  
  # replace NAs from guesses
  mutate(guess = replace(guess, guess<0, NA)) %>%
  
  # calculate error at each guess
  mutate(guess_error = length - guess)

```

## Identify and winnow down data to usable dyads

Next, we identify all dyads in which both participants responded the same number of times. This ensures that we include only dyads who experienced the full and correct experimental protocol.

```{r identify-complete-dyads}

# identify usable dyads
usable_dyads =  unique(setDT(info_df), by = c('experiment', 'dyad', 'participant', 
         'trial_type', 'trial_number', 'response_counter', 'guess_counter', 'accept_type', 
         'length', 'guess', 'guess_error', 'response_type', 'network_id')) %>%
  group_by(experiment,participant) %>%
  summarise(trials = max(trial_number),
            dyad = unique(dyad),
            responses = n()) %>%
  ungroup() %>%
  group_by(experiment, dyad) %>%
  mutate(participant = paste('p',(participant - min(participant)),sep='')) %>%
  spread(key = participant, value = responses) %>%
  ungroup() %>%
  dplyr::filter(p1 == p0 & trials == 24)

```

```{r print-usable-dyads, invisible=TRUE, echo=TRUE}

paste('Total usable dyads included: ',dim(usable_dyads)[1], sep='')

```

Now that we've figured out which dyads we should use, let's winnow down the dataframe to include only those dyads.

```{r winnow-data}

# winnow and recorder columns
winnowed_info_df = info_df %>%
  dplyr::filter(dyad %in% usable_dyads$dyad) %>%
  mutate(t = round(t,-1)) %>%
  select(experiment, t, dyad, participant, 
         trial_type, trial_number, response_counter, guess_counter, accept_type, 
         length, guess, guess_error, response_type, network_id)
winnowed_info_df = unique(setDT(winnowed_info_df), by = c('experiment', 'dyad', 'participant', 
         'trial_type', 'trial_number', 'response_counter', 'guess_counter', 'accept_type', 
         'length', 'guess', 'guess_error', 'response_type', 'network_id'))

```

## Export data

```{r export-data}

write.table(winnowed_info_df, './data/winnowed_data.csv', sep=',',
            append = FALSE, quote = FALSE, na = "NA", row.names = FALSE, col.names = TRUE)

```

***

# Data exploration and descriptive statistics

## Preliminaries

```{r exploration-prelim, warning = FALSE, error = FALSE, message = FALSE}

# clear our workspace
rm(list=ls())

# read in libraries and create functions
source('./supplementary-code/required_packages-pmc.r')

```

## Descriptive statistics

```{r mean-experiment-duration}

# get list of individual experiments included in the data
experiment_files = list.dirs('./data', recursive=FALSE)

# concatenate the files
participant_files = data.frame()
for (experiment in experiment_files){
  
  # read in the next experiment's files and add ID to each
  exp_id = strsplit(as.character(experiment),"/|-")[[1]][3]
  next_participant = read.table(paste(experiment,'/participant.csv',sep=''), sep=',',
                           header=TRUE, stringsAsFactors = FALSE) %>%
    mutate(experiment = exp_id)

  # append to group files
  participant_files = rbind.data.frame(participant_files, next_participant)
}

```

```{r mean-participation-time}

participant_df = participant_files %>%
  select(id, creation_time, end_time, experiment, worker_id) %>%
  mutate(creation_time = ymd_hms(creation_time)) %>%
  mutate(end_time = ymd_hms(end_time)) %>%
  mutate(duration = end_time - creation_time) %>%
  dplyr::filter(duration > 5 & duration < 30)
paste('Average participation: ',mean(participant_df$duration),' minutes',sep='')

```

