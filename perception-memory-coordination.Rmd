---
title: "Interpersonal coordination in perception and memory"
author: "A. Paxton, T. J. H. Morgan, J. Suchow, & T. L. Griffiths"
output: 
  html_document:
    number_sections: true
    keep_md: true
---

This R markdown provides the basis for our manuscript, "Interpersonal coordination in perception and memory" (Paxton, Morgan, Suchow & Griffiths, *in peparation*).

To run these analyses from scratch, you will need the following files:

* `./data/`: Contains experimental data. All data for included dyads are freely available in the OSF repository for the project: `https://osf.io/8fu7x/`.
* `./supplementary-code/required_packages-pmc.r`: Installs required libraries, if they are not already installed. **NOTE**: This should be run *before* running this script.
* `./supplementary-code/libraries_and_functions-pmc.r`: Loads in necessary libraries and creates new functions for our analyses.

Additional files will be created during the initial run that will help reduce processing time. Several of these files are available as CSVs from the OSF repository listed above.

**Written by**: A. Paxton (University of California, Berkeley)
<br>**Date last modified**: 19 October 2017

***

# Data preparation

***

## Preliminaries

```{r prep-prelim, warning = FALSE, error = FALSE, message = FALSE}

# clear our workspace
rm(list=ls())

# read in libraries and create functions
source('./supplementary-code/required_packages-pmc.r')
source('./supplementary-code/libraries_and_functions-pmc.r')

```

***

## Read in all data

```{r read-in-data, warning = FALSE, error = FALSE, message = FALSE}

# get list of individual experiments included in the data
experiment_files = list.dirs('./data', recursive=FALSE)

# concatenate the files
vector_files = data.frame()
info_files = data.frame()
for (experiment in experiment_files){
  
  # read in the next experiment's files and add ID to each
  exp_id = strsplit(as.character(experiment),"/|-")[[1]][3]
  next_vector = read.table(paste(experiment,'/vector.csv',sep=''), sep=',',
                           header=TRUE, stringsAsFactors = FALSE) %>%
    mutate(experiment = exp_id)
  next_info = read.table(paste(experiment,'/info.csv',sep=''), sep=',',
                         header=TRUE, stringsAsFactors = FALSE) %>%
    mutate(experiment = exp_id)

  # append to group files
  vector_files = rbind.data.frame(vector_files, next_vector)
  info_files = rbind.data.frame(info_files, next_info)
}

```

## Identify dyads from vector data

In order to figure out which participants' nodes were connected to one another in dyads, we use the creation time of vectors between nodes (excluding the stimulus-creating node). We then use that information to identify which stimuli were sent to which dyads.

```{r concatenate-data, warning = FALSE, error = FALSE, message = FALSE}

# identify time and nodes for distinct dyads
vector_df = vector_files %>%
  
  # convert time to integer and winnow out unnecessary variables and nodes
  mutate(t = round(as.numeric(ymd_hms(creation_time)), 0)) %>%
  select(experiment, t, origin_id, destination_id, network_id) %>%
  dplyr::filter(!origin_id == 1) %>%
  
  # group by experiment and time to identify possible dyads
  group_by(experiment, t) %>%
  { mutate(ungroup(.), 
           dyad = group_indices(.)) } %>%
  ungroup() %>%
  
  # export only the necessary variables
  select(experiment, t, dyad, origin_id) %>%
  as.data.frame

# figure out which stimuli were sent to which dyads
stimuli_df = info_files %>%
  mutate(t = round(as.numeric(ymd_hms(creation_time)), 0)) %>%
  dplyr::filter(origin_id == 1) %>%
  select(experiment, t, contents) %>%
  full_join(., vector_df,
            by = c('experiment', 't'))
  
# combine dyad information and individual participant information
dyad_df = full_join(vector_df, stimuli_df, by = c('t','experiment','dyad','origin_id')) %>% 
  select(-t) %>%
  distinct()

```

## Prepare info dataframe

```{r process-infos, warning = FALSE, error = FALSE, message = FALSE}

# load in infos
info_df = info_files %>%
  
  # filter out stimulus nodes
  dplyr::filter(!origin_id == 1) %>%
  
  # convert time and get rid of unnecessary variables
  select(t, property3, origin_id, network_id, contents) %>%
  mutate(t = round(as.numeric(ymd_hms(creation_time)), 0)) %>%
  
  # read in `contents` as JSONs and nix the JSON column
  cbind(.,
        jsonlite::stream_in(textConnection(.$contents))) %>%
  select(-contents) %>%
  
  # merge info datafarme with dyad number information
  full_join(., dyad_df,
            by = c('origin_id','network_id')) %>%
  
  # rename a whole slew of variables
  dplyr::rename(participant = origin_id,
                stimulus_list = contents,
                trial_type = trialType,
                trial_number = trialNumber,
                guess_counter = guessCounter,
                response_counter = responseCounter,
                accept_type = acceptType,
                response_type = responseType) %>%
  
  # get rid of unnecessary variables, get unique columns, and arrange dataframe
  select(-t, -property3, -finalAccuracy) %>%
  distinct() %>%
  dplyr::arrange(dyad, participant, trial_number, response_counter) %>%
  
  # replace NAs from guesses
  mutate(guess = replace(guess, guess<0, NA)) %>%
  
  # calculate error at each guess
  mutate(guess_error = length - guess)

