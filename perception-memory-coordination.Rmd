---
title: "Interpersonal coordination in perception and memory"
author: "A. Paxton, T. J. H. Morgan, J. Suchow, & T. L. Griffiths"
output: 
  html_document:
    number_sections: true
    keep_md: true
---

This R markdown provides the basis for our manuscript, "Interpersonal coordination in perception and memory" (Paxton, Morgan, Suchow & Griffiths, *in peparation*).

To run these analyses from scratch, you will need the following files:

* `./data/`: Contains experimental data. All data for included dyads are freely available in the OSF repository for the project: `https://osf.io/8fu7x/`.
* `./supplementary-code/required_packages-pmc.r`: Installs required libraries, if they are not already installed. **NOTE**: This should be run *before* running this script.
* `./supplementary-code/libraries_and_functions-pmc.r`: Loads in necessary libraries and creates new functions for our analyses.

Additional files will be created during the initial run that will help reduce processing time. Several of these files are available as CSVs from the OSF repository listed above.

**Written by**: A. Paxton (University of California, Berkeley)
<br>**Date last modified**: 19 October 2017

***

# Data preparation

***

## Preliminaries

```{r prep-prelim, warning = FALSE, error = FALSE, message = FALSE}

# clear our workspace
rm(list=ls())

# read in libraries and create functions
source('./supplementary-code/required_packages-pmc.r')
source('./supplementary-code/libraries_and_functions-pmc.r')

```

***

## Concatenate experiment files

```{r concatenate-data, warning = FALSE, error = FALSE, message = FALSE}

# get list of individual experiments included in the data
experiment_files = list.dirs('./data', recursive=FALSE)

# concatenate the files
vector_files = data.frame()
info_files = data.frame()
questionnaire_files = data.frame()
node_files = data.frame()
for (experiment in experiment_files){
  
  # read in the next experiment's files and add ID to each
  exp_id = strsplit(as.character(experiment),"/|-")[[1]][3]
  next_vector = read.table(paste(experiment,'/vector.csv',sep=''), sep=',',
                           header=TRUE, stringsAsFactors = FALSE) %>%
    mutate(experiment = exp_id)
  next_info = read.table(paste(experiment,'/info.csv',sep=''), sep=',',
                         header=TRUE, stringsAsFactors = FALSE) %>%
    mutate(experiment = exp_id)
  next_q = read.table(paste(experiment,'/question.csv',sep=''), sep=',',
                           header=TRUE, stringsAsFactors = FALSE) %>%
    mutate(experiment = exp_id)
  next_node = read.table(paste(experiment,'/node.csv',sep=''), sep=',',
                           header=TRUE, stringsAsFactors = FALSE) %>%
    mutate(experiment = exp_id)

  # append to group files
  vector_files = rbind.data.frame(vector_files, next_vector)
  info_files = rbind.data.frame(info_files, next_info)
  questionnaire_files = rbind.data.frame(questionnaire_files, next_q)
  node_files = rbind.data.frame(node_files, next_node)

}

```

## Identify dyads from vector data

In order to figure out which participants' nodes were connected to one another in dyads, we use the vectors created between nodes (excluding the stimulus-creating node). We then use that information to identify which stimuli were sent to which dyads.

```{r identify-dyads, warning = FALSE, error = FALSE, message = FALSE}

# use the vectors connecting the nodes to identify pairs
vector_df = vector_files %>%
  
  # convert time to integer and winnow out unnecessary variables and nodes
  mutate(t = round(as.numeric(ymd_hms(creation_time)), 0)) %>%
  select(experiment, t, origin_id, destination_id, network_id) %>%
  dplyr::filter(!origin_id == 1) %>%
  
  # find pairs from vector files
  group_by(experiment, t) %>%
  mutate(min_id = pmin(origin_id,destination_id)) %>%
  mutate(max_id = pmax(origin_id,destination_id)) %>%
  ungroup() %>%
  
  # get unique pairs and number them
  select(-origin_id, -destination_id) %>%
  distinct() %>%
  mutate(dyad = seq_along(min_id)) %>%

  # gather the participants into a single column
  gather(key="id",value="participant", min_id, max_id) %>%
  select(-id)

# figure out which stimuli were sent to which dyads
dyad_df = info_files %>%
  mutate(t = round(as.numeric(ymd_hms(creation_time)), 0)) %>%
  dplyr::filter(origin_id == 1) %>%
  select(experiment, t, contents) %>%
  full_join(., vector_df,
            by = c('experiment', 't')) %>%
  select(-t)

```

## Prepare dataframe

We now take the concatenated files and begin processing, including de-duplication of dataset.

The structure of the experiment sometimes led to near-duplicate rows to be sent to the server to manage partner communication. We must now identify these near-duplicates and strip them out. We can best identify these by using the `response_counter` variable: A properly de-duplicated dataset should have only 1 row per `response_counter` value in each trial for each participant.

```{r process-infos, warning = FALSE, error = FALSE, message = FALSE}

info_df = info_files %>% ungroup() %>%
  
  # filter out stimulus nodes
  dplyr::filter(!origin_id == 1) %>%
  
  # convert time and get rid of unnecessary variables
  mutate(t = round(as.numeric(ymd_hms(creation_time)), 0)) %>%
  select(experiment, t, property3, origin_id, network_id, contents) %>%
    
  # read in `contents` as JSONs
  cbind(., jsonlite::stream_in(textConnection(.$contents))) %>%

  # rename a whole slew of variables
  dplyr::rename(participant = origin_id,
                trial_type = trialType,
                trial_number = trialNumber,
                guess_counter = guessCounter,
                response_counter = responseCounter,
                accept_type = acceptType,
                response_type = responseType) %>%
  
  # get rid of unnecessary variables and arrange rows
  select(-property3, -finalAccuracy, -contents) %>%
  dplyr::arrange(experiment, participant, trial_number, response_counter) %>%
  
  # remove the automatically generated infos that produced NAs in `guess`
  dplyr::filter(!is.na(guess)) %>%
  
  # determine uniqueness without considering time or response_type
  group_by(experiment, participant, network_id, trial_type,
           trial_number, guess_counter, response_counter) %>%
  summarise_all(first) %>%
  ungroup() %>%
  
  # replace NAs from guesses and calculate error with each guess
  mutate(guess = replace(guess, guess<0, NA)) %>%
  mutate(guess_error = length - guess) %>%
  
  # merge info dataframe with dyad number information
  full_join(., dyad_df,
            by = c('experiment', 'participant','network_id')) %>%
  dplyr::rename(stimulus_list = contents)

```

```{r print-sanity-check-for-duplicate-issues, invisible=TRUE, echo=FALSE}

# sanity check
sanity_df = info_df %>% ungroup() %>%
  
  # count number of times we see the same response counter
  group_by(experiment, participant, trial_type, trial_number, guess_counter, response_counter) %>%
  summarise(n = n()) %>%
  ungroup() %>%
  
  # filter to include only test-condition duplicates
  dplyr::filter(n!=1 & trial_type=="test") %>%
  
  # join with the main dataset to check it out
  inner_join(., info_df, 
             by = c("experiment", "participant", "trial_type", 
                    "trial_number", "guess_counter", "response_counter")) %>%
  
  # identify whether any identiifed duplicate rows have diferent accept_type values
  group_by(experiment, participant, trial_type, trial_number, guess_counter, response_counter) %>%
  dplyr::filter(length(unique(accept_type))!=1) %>%
  ungroup()

# print sanity check
cat('Problematic rows identified (i.e., duplicates with differing accept types): ',dim(sanity_df)[1],sep='')

```

## Identify and winnow down data to usable dyads

Next, we identify all dyads in which both participants responded the same number of times. This ensures that we include only dyads who experienced the full and correct experimental protocol.

```{r identify-complete-dyads}

# identify usable dyads
usable_dyads = info_df %>%
  
  # count the number of infos and trials per participant
  group_by(experiment,participant) %>%
  summarise(trials = max(trial_number),
            dyad = ifelse(length(unique(dyad)==1),
                          unique(dyad),
                          NA),
            infos = n()) %>%
  ungroup() %>%
  na.omit() %>%
  
  # count the infos sent by each participant in each dyad
  group_by(experiment, dyad) %>%
  mutate(participant = paste('p',(participant - min(participant)),sep='')) %>%
  spread(key = participant, value = infos) %>%
  ungroup() %>%
  mutate(difference_in_responses = abs(p1-p0)) %>%
  
  # filter out anyone who didn't have the same number of infos and who didn't complete 24 trials
  dplyr::filter(trials==24 & difference_in_responses==0) %>%
  na.omit()

```

```{r print-usable-dyads, invisible=TRUE, echo=FALSE}

cat('Total dyads with strictly paired data for all trials: ',dim(usable_dyads)[1], sep='')

```

Now that we've figured out which dyads we should use, let's winnow down the dataframe to include only those dyads.

```{r winnow-data}

# winnow and recorder columns
winnowed_info_df = info_df %>%
  dplyr::filter(dyad %in% usable_dyads$dyad) %>%
  mutate(t = round(t,-1)) %>%
  select(experiment, t, dyad, participant, 
         trial_type, trial_number, response_counter, guess_counter, accept_type, 
         length, guess, guess_error, response_type, network_id)
winnowed_info_df = unique(setDT(winnowed_info_df), by = c('experiment', 'dyad', 'participant', 
         'trial_type', 'trial_number', 'response_counter', 'guess_counter', 'accept_type', 
         'length', 'guess', 'guess_error', 'response_type', 'network_id'))

```

For sanity, let's also check that everyone included in our winnowed dataset completed both training and test trials.

```{r sanity-check-for-training-and-test}

# ensure that everyone completed both training and test
only_one_trial_type = winnowed_info_df %>% ungroup() %>%
  group_by(experiment, participant, trial_type) %>%
  distinct() %>%
  group_by(experiment, participant)%>%
  summarize(n=n()) %>%
  dplyr::filter(n!=2)

```

```{r print-problem-participants, invisible=TRUE, echo=FALSE}

cat('Included participants who did not undergo training and testing rounds: ',dim(only_one_trial_type)[1], sep='')

```

## Add questionnaire data

In the experiment's current form, different tables include different information, and some tables present the same information under different labels. This is true for questionnaire data. To accurately pair individuals' guess data with their questionnaire responses, we match the `participant_id` variables in `node_df` and `question_df`, and we join the `id` variable in `node_df` with the `participant` variable in `info_df`.

```{r add-questionnaire-data}

# clean up questionnaire data by converting the stringified JSONs to a new variable
question_df = questionnaire_files %>% ungroup() %>%
  select(experiment, participant_id, response) %>%
  cbind(., jsonlite::stream_in(textConnection(.$response))) %>%
  select(-response)

# clean up the node dataframe
node_df = node_files %>% ungroup() %>%
  select(experiment, participant_id, id) %>%
  na.omit()

# join questionnaire data wth infos and remove any participants whose survey data we don't have
winnowed_info_df = left_join(question_df, node_df,
                                by=c('experiment','participant_id')) %>%
  left_join(winnowed_info_df, .,
                              by=c('experiment','participant' = 'id')) %>%
  drop_na(cooperative_partner, cooperative_self, trust_partner, trust_self, engagement, difficulty)

```

```{r identify-questionnaire-dyads}

# identify how many dyads have matching infos and complete questionnaire data
usable_question_dyads = winnowed_info_df %>% ungroup() %>%
  select(experiment, dyad, participant) %>%
  distinct() %>%
  group_by(experiment, dyad) %>%
  summarise(included_p = n()) %>%
  ungroup() %>%
  dplyr::filter(included_p==2)

# if needed, remove dyads who didn't have questionnaire data
winnowed_info_df = winnowed_info_df %>% ungroup() %>%
  dplyr::filter(dyad %in% usable_question_dyads$dyad)

```

```{r print-quesionnaire-dyads, invisible=TRUE, echo=FALSE}

cat('Total dyads with all guess and questionnaire data: ',dim(usable_question_dyads)[1], sep='')

```

## Create unique dyad and participant IDs across all experiments

Dallinger provides numeric IDs for each participant that are unique only within each experiment. Therefore, we create participant and dyad identifiers that are unique across the entire dataset.

```{r create-unique-ids}

# create unique dyad IDs
unique_dyad_ids = winnowed_info_df %>% ungroup() %>%
  select(experiment, dyad) %>%
  distinct() %>%
  mutate(unique_dyad = row_number())

# create unique participant IDs
unique_participant_ids = winnowed_info_df %>% ungroup() %>%
  select(experiment, participant) %>%
  distinct() %>%
  mutate(unique_participant = row_number())

# merge both into the main dataframe and rename
winnowed_info_df = right_join(unique_participant_ids, winnowed_info_df,
                             by=c('experiment', 'participant')) %>%
  right_join(unique_dyad_ids, ., by=c('experiment','dyad')) %>%
  dplyr::rename(original_participant = participant,
                original_dyad = dyad,
                participant = unique_participant,
                dyad = unique_dyad) %>%
  dplyr::arrange(experiment, participant, trial_number, response_counter)

```


## Increment all counters by 1

Data were collected using Pythonic counters (i.e., starting from 0). We'll here update the dataframe to reflect R conventions (i.e., starting from 1).

```{r r-counters}

winnowed_info_df = winnowed_info_df %>%
  mutate(trial_number = trial_number + 1) %>%
  mutate(response_counter = response_counter + 1) %>%
  mutate(guess_counter = guess_counter + 1)

```

## Normalize error by maximum possible error

Because stimuli line lengths could range from 1-100, each trial provided a bound on the total possible guess error.  As a result, we need to normalize each guess error by the maximum *possible* error for that trial.

```{r normalize-error}

winnowed_info_df = winnowed_info_df %>% ungroup() %>%
  mutate(normalized_error = guess_error/max(abs(100-length),abs(length-100)))

```

## Create training accuracy metric

```{r training-improvement}

# create a slope to see how quickly they improved
winnowed_info_df = winnowed_info_df %>% ungroup() %>%
  select(participant, trial_type, trial_number, normalized_error) %>%
  na.omit() %>%
  dplyr::filter(trial_type == 'train') %>%
  group_by(participant) %>%
  do(broom::tidy(lm(abs(.$normalized_error) ~ .$trial_number))) %>%
  dplyr::filter(term=='.$trial_number') %>%
  select(participant, estimate) %>%
  dplyr::rename(training_improvement = estimate) %>%
  left_join(winnowed_info_df, .,
            by='participant')

```

```{r plot-training_slopes, echo=FALSE, warning = FALSE, error = FALSE, message = FALSE}

ggplot(dplyr::filter(winnowed_info_df, 
                     trial_type=='train'), 
       aes(x = trial_number,
           y = normalized_error)) +
  geom_line(aes(color=as.factor(participant))) +
  scale_color_viridis(discrete=TRUE) +
  stat_smooth() +
  ylab('Absolute error of guess') +
  scale_x_continuous(breaks=c(1,5,10)) +
  xlab('Training trial') +
  ggtitle('Accuracy of individual participants across training trials') +
  theme(legend.position="none")

```

## Remove outliers and missed guesses

Likely due to the timing-out mechanism, a minority of guesses provided wildly inaccurate estimates of the stimuli. 

```{r identify-likely-outliers}

# figure out how many outliers there were
likely_outlier_responses = winnowed_info_df %>% ungroup() %>%
  dplyr::filter(abs(guess_error) > 30)

# figure out how many total guesses were submitted
total_submitted_guesses = winnowed_info_df %>% ungroup() %>%
  group_by(participant, trial_number) %>%
  summarise(total_guesses = max(guess_counter))

```

```{r print-likely-outliers, echo=FALSE}

# print out raw number and proportion of outliers
cat('Outlier guesses: ',dim(likely_outlier_responses)[1],' (',
    round(dim(likely_outlier_responses)[1]/sum(total_submitted_guesses$total_guesses),4)
    ,'% of total guesses)', sep='')

```


Given the low rate of occurrence, we consider these to be outliers and remove them from the dataset.

```{r replace-likely-errors}

# replace hugely off-base numbers with missing data
winnowed_info_df = winnowed_info_df %>%
  mutate(guess = replace(guess, abs(guess_error)>30, NA)) %>%
  mutate(guess_error = replace(guess_error, abs(guess_error)>30, NA))

```

```{r plot-normalized-error-over-all-trials, echo=FALSE, warning = FALSE, error = FALSE, message = FALSE}

# figure out what our equal x-axis limits will be
x_limit = winnowed_info_df %>% ungroup() %>%
  na.omit() %>%
  summarise(lim = max(abs(normalized_error))) %>%
  .$lim

# create plot
ggplot(winnowed_info_df,
       aes(x = normalized_error)) + 
  geom_histogram(aes(fill = factor(trial_number)),bins=30) +
  scale_fill_viridis(discrete=TRUE,
                     breaks=c('1',
                              '5',
                              '10',
                              '15',
                              '20',
                              '25'),
                     labels=c('First',
                              '',
                              '',
                              '',
                              '',
                              'Last'),
                     name = "Trial") +
  xlab('Normalized error') +
  ylab('Count') +
  xlim(-x_limit, x_limit) +
  ggtitle('Normalized error over all trials')
  
```

## Export data

```{r export-data}

write.table(winnowed_info_df, './data/winnowed_data.csv', sep=',',
            append = FALSE, quote = FALSE, na = "NA", row.names = FALSE, col.names = TRUE)

```

***

# Data exploration and descriptive statistics

## Preliminaries

```{r exploration-prelim, warning = FALSE, error = FALSE, message = FALSE}

# clear our workspace
rm(list=ls())

# read in libraries and create functions
source('./supplementary-code/required_packages-pmc.r')

```

## Descriptive statistics

```{r mean-experiment-duration}

# get list of individual experiments included in the data
experiment_files = list.dirs('./data', recursive=FALSE)

# concatenate the files
participant_files = data.frame()
for (experiment in experiment_files){
  
  # read in the next experiment's files and add ID to each
  exp_id = strsplit(as.character(experiment),"/|-")[[1]][3]
  next_participant = read.table(paste(experiment,'/participant.csv',sep=''), sep=',',
                           header=TRUE, stringsAsFactors = FALSE) %>%
    mutate(experiment = exp_id)

  # append to group files
  participant_files = rbind.data.frame(participant_files, next_participant)
}

```

```{r mean-participation-time}

participant_df = participant_files %>%
  select(id, creation_time, end_time, experiment, worker_id) %>%
  mutate(creation_time = ymd_hms(creation_time)) %>%
  mutate(end_time = ymd_hms(end_time)) %>%
  mutate(duration = end_time - creation_time) %>%
  dplyr::filter(duration > 5 & duration < 30)
cat('Average participation: ',mean(participant_df$duration),' minutes',sep='')

```

***

# Psychonomics 2017 poster

This section presents the data analysis for the Psychonomics 2017 poster, "Exploring social behavior with Dallinger, an open-source experiment automation tool" (A. Paxton, T. J. H. Morgan, J. Suchow, & T. L. Griffiths, forthcoming). The poster largely presents Dallinger and its specific capabilities of interest to individuals running social psychology experiments, but an analysis of the pilot data from the present study is included as a demonstration.

## Preliminaries

Clear the workspace, load in required libraries and functions, and read in the prepared dataset.

```{r analysis-prelim, warning = FALSE, error = FALSE, message = FALSE}

# clear our workspace
rm(list=ls())

# read in libraries and create functions
source('./supplementary-code/libraries_and_functions-pmc.r')

# read in dataset
winnowed_info_df = read.table('./data/winnowed_data.csv', sep=',',header = TRUE)

```

## Data preparation


### Create interaction terms

```{r create-orthogonal-polynomials}

# create first- and second-order orthogonal polynomials for trial
raw_lag = min(winnowed_info_df$trial_number):max(winnowed_info_df$trial_number)
lag_vals = data.frame(raw_lag)
lag_offset = (0-min(raw_lag)) + 1
trial = stats::poly((raw_lag + lag_offset), 2)
lag_vals[, paste("ot", 1:2, sep="")] = trial[lag_vals$raw_lag + lag_offset, 1:2]

# join it to the original data table
winnowed_info_df = left_join(winnowed_info_df,lag_vals, by = c("trial_number" = "raw_lag"))

```

```{r create-time-interactions}

winnowed_info_df = winnowed_info_df %>% ungroup() %>%
  plyr::rename(.,
               c("conv.type"="convers",
                 "cond"="condition")) %>%
  mutate(condition = condition-.5) %>%
  mutate(convers = convers-.5) %>%
  mutate(condition.convers = condition * convers) %>%

  # first-order polynomials
  mutate(condition.ot1 = condition * ot1) %>%
  mutate(convers.ot1 = convers * ot1) %>%
  mutate(condition.convers.ot1 = condition * convers * ot1) %>%

  # second-order polynomials
  mutate(condition.ot2 = condition * ot2) %>%
  mutate(convers.ot2 = convers * ot2) %>%
  mutate(condition.convers.ot2 = condition * convers * ot2) %>%

  # polynomial interactions
  mutate(ot1.ot2 = ot1 * ot2) %>%
  mutate(condition.ot1.ot2 = condition * ot1 * ot2) %>%
  mutate(convers.ot1.ot2 = convers * ot1 * ot2) %>%
  mutate(condition.convers.ot1.ot2 = condition * convers * ot1 * ot2)

```

### Create standardized dataset
